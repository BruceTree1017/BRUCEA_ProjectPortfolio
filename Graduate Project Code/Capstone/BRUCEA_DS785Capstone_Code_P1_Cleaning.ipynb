{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "958f1f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Active customers is: 2311\n"
     ]
    }
   ],
   "source": [
    "### Adam Bruce, Started December, 2024. \n",
    "### Data was current as of January 1st, 2025\n",
    "### The following code/descriptors help solve the assignment optimization problem for Turf Badger's Stevens Point \n",
    "# Office (S Corporation)\n",
    "\n",
    "### Load Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "new_space = lambda: print(\" \")\n",
    "\n",
    "### Load the dataset\n",
    "\n",
    "# The dataset customers.csv contains information on ALL active, recurring customer accounts!\n",
    "# Cleaning will need to be performed based on information found in the data\n",
    "\n",
    "SP_customers = pd.read_csv('Customers.csv')\n",
    "\n",
    "# If wanting A quick look at the dataset:\n",
    "#print(SP_customers.head(2))\n",
    "#new_space()\n",
    "\n",
    "# Count of Customers in the dataset:\n",
    "print(f'The number of Active customers is: {SP_customers.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc7863bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005              Hilton Garden Inn\n",
      "1856    Bridge Street Partners, LLP\n",
      "2236         Lazy Meadows Homes LLC\n",
      "Name: Company_Name, dtype: object\n",
      " \n",
      "There are 0 rows with missing data remaining.\n",
      " \n",
      " \n",
      "The final number of Active customers is: 2282\n"
     ]
    }
   ],
   "source": [
    "### Cleaning \n",
    "### NOTE: Some # values by print statements are used to reduce clutter, to look at the output undue the # by the print statement!\n",
    "### NOTE: Because the latitude and longitude are available, we do not need the address column for location purposes.\n",
    "# It could be useful for the administrator, Tricia, later on though, so it is kept.\n",
    "\n",
    "\n",
    "## To start, column names will be underscored and condensed to make work going forward easier\n",
    "# For example, Supscription Status will become Subscription_Status\n",
    "SP_customers.rename(columns={'Customer ID': 'Cust_ID', 'Last Name': 'Last', 'First Name': 'First', 'Sold Date': 'Sold_Date', 'Company Name': 'Company_Name',\n",
    "                            'Subscription Contract Value': 'Contract_Value', 'Subscription Category': 'Subscription_Category'}, inplace=True)\n",
    "\n",
    "# Now, nan values must be addressed in the dataset.\n",
    "# First, lets grab the company customers from the Company_Name column in the dataset\n",
    "company_data = SP_customers.loc[~SP_customers['Company_Name'].isna(), 'Company_Name']\n",
    "print(company_data)\n",
    "new_space()\n",
    "# There are three companies found here:Hilton Garden Inn, Bridge Street Partners, LLP, and Lazy Meadows Homes LLC\n",
    "\n",
    "# Now, lets look at the NA rows for the FIRST and LAST NAME Columns\n",
    "First_nan_data = SP_customers[SP_customers['First'].isna()]\n",
    "# print(First_nan_data)\n",
    "# new_space()\n",
    "# There are no cases where First Name is Empty! Thus, we can look to see if the first names match the company names\n",
    "# if this is true we can drop the company name column We will filter by indexes found above\n",
    "\n",
    "First_company_data = SP_customers.filter(items=[1008, 1862, 2242], axis=0)\n",
    "# print(First_company_data['First'])\n",
    "# new_space()\n",
    "\n",
    "# We see the owners are listed as first and last names in this case. We will replace the owners with the company name\n",
    "# Last will be replaced with a blank string \" \"\n",
    "\n",
    "# Make the company name dataframe (undue # note to print)\n",
    "company_data = pd.DataFrame(company_data)\n",
    "# print(company_data)\n",
    "\n",
    "# Replace first with company name in cases of interest\n",
    "SP_customers.loc[company_data.index, 'First'] = company_data['Company_Name']\n",
    "# Now replace the index values for LAST with blank strings!\n",
    "SP_customers.loc[1005,'Last'] = \"\"\n",
    "SP_customers.loc[1856,'Last'] = \"\"\n",
    "SP_customers.loc[2236,'Last'] = \"\"\n",
    "\n",
    "# Now look at the dataframe for these specific indices!\n",
    "new_company_data = SP_customers.filter(items=[1008, 1862, 2242], axis=0)\n",
    "#print(new_company_data)\n",
    "#new_space()\n",
    "\n",
    "# NOW WE CAN DROP THE COMPANY NAME COLUMN ENTIRELY!\n",
    "SP_customers_2 = SP_customers.drop(columns=['Company_Name'])\n",
    "\n",
    "# We now recheck the NA values remaining\n",
    "null_data_1 = SP_customers_2[SP_customers_2.isnull().any(axis=1)]\n",
    "# print(null_data_1)\n",
    "# new_space()\n",
    "\n",
    "# There is one nan value remaining for row 243, a company that has no last name value. It will be replaced with a blank string like the other companies!\n",
    "SP_customers_2.loc[243,'Last'] = \"\"\n",
    "\n",
    "# Now lets get a count of the null data left!\n",
    "print(f'There are {SP_customers_2.isnull().sum().sum()} rows with missing data remaining.')\n",
    "new_space()\n",
    "\n",
    "# We create the final \"Customer\" column by combining First and Last! We also drop the combined columns\n",
    "SP_customers_2['Customer'] = SP_customers_2['First'] + \" \" + SP_customers_2['Last']\n",
    "SP_customers_3 = SP_customers_2.drop(columns=['First', 'Last'])\n",
    "\n",
    "# Check the head of this dataset and for null values (should be none)\n",
    "# print(SP_customers_3.head(1))\n",
    "# print(f'There are {SP_customers_3.isnull().sum().sum()} rows with missing data remaining.')\n",
    "\n",
    "\n",
    "\n",
    "## Next we will address the total yearly services for each contract. \n",
    "# Sold_Date indicates the month of service start for each customer. We need only the month from this date column.\n",
    "# So we will extract it and make it a new column \"Start_Month\" before dropping the sold_date column\n",
    "\n",
    "SP_customers_3[['Start_Month','Start_Day', 'Start_Year']] = SP_customers_3['Sold_Date'].str.split('/',expand=True)\n",
    "#print(SP_customers_3.head(1))\n",
    "#new_space()\n",
    "\n",
    "# Drop the unneeded columns\n",
    "SP_customers_4 = SP_customers_3.drop(['Sold_Date','Start_Day','Start_Year'], axis=1)\n",
    "#print(SP_customers_4.head(1))\n",
    "#new_space()\n",
    "\n",
    "## We also drop the Address column because it contains sensitive information that isn't needed for solving the problem.\n",
    "## because we can cluster based on latitude and longitude!\n",
    "\n",
    "SP_customers_4 = SP_customers_4.drop(['Address'], axis=1)\n",
    "\n",
    "\n",
    "## The service entries X Fleat & Tick and Lawn - FERT TEMP are data entry errors by sales representatives\n",
    "## The X FLEA & TICK should just be FLEA & TICK while 'Lawn - FERT TEMP' should be 'Fertilization' Per Tricia\n",
    "\n",
    "# Identify unique subsciption types\n",
    "#unique_services = SP_customers_4['Subscription'].unique()\n",
    "#print(unique_services)\n",
    "\n",
    "# Identify Data Entry Errors and fix\n",
    "# X Flea & Tick to Flea & Tick & 'Lawn - FERT/TEMP' to Fertilization\n",
    "SP_customers_4.Subscription = SP_customers_4.Subscription.replace({'X Flea & Tick': \"Flea & Tick\", 'Lawn - FERT TEMP': \"Fertilization\"})\n",
    "new_space() \n",
    "\n",
    "## Per the Administrator Tricia and branch owner James, bed bug, 'WL - Foundation Exclusion', 'Flea & Tick',\n",
    "## 'WL - Wildlife/Full Exclusion Services', and 'WL - Rodent/Wildlife Trapping'\n",
    "## are single services that need not be accounted for in a service zone total.\n",
    "## So rows of these service types will be dropped.\n",
    "\n",
    "SP_customers_4 = SP_customers_4.drop(SP_customers_4[(SP_customers_4['Subscription'] == 'WL - Rodent/Wildlife Trapping') |\n",
    "                                                   (SP_customers_4['Subscription'] == 'Flea & Tick') |\n",
    "                                                   (SP_customers_4['Subscription'] == 'WL - Foundation Exclusion') |\n",
    "                                                   (SP_customers_4['Subscription'] == 'WL - Wildlife/Full Exclusion Services') |\n",
    "                                                   (SP_customers_4['Subscription'] == 'Pest - Bed Bug')].index)\n",
    "\n",
    "# Identify if the rows were properly dropped by looking at the unique services!\n",
    "# Identify unique subsciption types\n",
    "# unique_services = SP_customers_4['Subscription'].unique()\n",
    "# print(unique_services)\n",
    "\n",
    "## An important constraint for the zones will be the net income per year for each technician. \n",
    "## Per Tricia, the net per year MUST BE GREATER THAN OR EQUAL TO 20,000 USD\n",
    "## Per Tricia, the net takehome per service contract total for technicians is 14%\n",
    "## Thus, a new column, Tech_Takehome will be calculated at 0.14*Contract_Value\n",
    "\n",
    "# Create the new column\n",
    "SP_customers_4['Tech_Takehome'] = round(SP_customers_4['Contract_Value'] * 0.14, 2)\n",
    "#print(SP_customers_4.head(1))\n",
    "#new_space()\n",
    "\n",
    "# Count final number of Customers in the dataset:\n",
    "print(f'The final number of Active customers is: {SP_customers_4.shape[0]}')\n",
    "\n",
    "## Now we save the cleaned data to a csv file!\n",
    "\n",
    "SP_customers_4.to_csv('SP_Customers_Clean.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
