---
title: "DS740 Midterm Code"
author: "Adam Bruce"
date: "2024-03-08"
output: html_document
---

```{r, echo = FALSE, include = FALSE}
library(dplyr)
library(ggformula)
library(readr)
library(rpart)
library(randomForest)
library(xgboost)
library(rattle)
library(caret)
library(gridExtra)
library(corrplot)
library(ggplot2)
library(pROC)
library(gplots)
library(simexaft) # for BHS data
library(nnet)
library(NeuralNetTools)
library(RColorBrewer)
library(VIM)
library(GGally)
```

```{r, echo = FALSE, include = FALSE, warning = FALSE, fig.height = 12, fig.width = 12}
################## Exploratory Analysis/Data Cleaning

Athletes <- read_csv("~/Desktop/DS740 Data Mining/Midterm Project/Athletes.csv")

# Transform Variables

Athletes <- Athletes %>% mutate(Ht = Ht * 0.394, Wt = Wt * 2.21)

## NA Values?

sum(is.na(Athletes))

#### Choosing Parameters?

# Classification With Mtry = sqrt(predictors), so sqrt(12) = 3.46 range 0 to 10.
# Classigicatin with KNN will use range of K between 1 and 202 in steps of 2 for our observations.

# Boxplots 

color_blind_friendly <- c("#CC7917", "#0072B2","#CC79A7")

## Boxplot Ht

Boxplot_Ht_Sport <- 
  ggplot(Athletes, aes(x = Sport_group, y = Ht, color = Sport_group))+ 
  geom_boxplot(size = 0.75)+
  ylab("Height")+
  xlab("Sport Group")+
  ggtitle("Figure 1: Distribution of Heights by Various Sport Groups
                  for 202 Australian Athletes")+
  scale_color_manual(values = color_blind_friendly, name = "Model Version")+
  theme_classic()

## Boxplot Wt

Boxplot_Wt_Sport <- 
  ggplot(Athletes, aes(x = Sport_group, y = Wt, color = Sport_group))+ 
  geom_boxplot(size = 0.75)+
  ylab("Weight")+
  xlab("Sport Group")+
  ggtitle("Figure 2: Distribution of Weights by Various Sport Groups
                  for 202 Australian Athletes")+
  scale_color_manual(values = color_blind_friendly, name = "Model Version")+
  theme_classic()

## Boxplot LBN

Boxplot_LBM_Sport <- 
  ggplot(Athletes, aes(x = Sport_group, y = LBM, color = Sport_group))+ 
  geom_boxplot(size = 0.75)+
  ylab("Lean Body Mass")+
  xlab("Sport Group")+
  ggtitle("Figure 3: Lean Body Mass by Various Sport Groups
                  for 202 Australian Athletes")+
  scale_color_manual(values = color_blind_friendly, name = "Model Version")+
  theme_classic()

## Boxplot RBC

Boxplot_RCC_Sport <- 
  ggplot(Athletes, aes(x = Sport_group, y = RCC, color = Sport_group))+ 
  geom_boxplot(size = 0.75)+
  ylab("Red Blood Cell Count")+
  xlab("Sport Group")+
  ggtitle("Figure 5: Red Blood Cell Counts by Various Sport Groups
                  for 202 Australian Athletes")+
  scale_color_manual(values = color_blind_friendly, name = "Model Version")+
  theme_classic()

## Boxplot WBC

Boxplot_WCC_Sport <- 
  ggplot(Athletes, aes(x = Sport_group, y = WCC, color = Sport_group))+ 
  geom_boxplot(size = 0.75)+
  ylab("White Blood Cell Count")+
  xlab("Athlete Sport Group")+
  ggtitle("Figure 6: White Blood Cell Counts by Various Sport Groups
                  for 202 Australian Athletes")+
  scale_color_manual(values = color_blind_friendly, name = "Model Version")+
  theme_classic()

## Boxplot Hc

Boxplot_Hc_Sport <- 
  ggplot(Athletes, aes(x = Sport_group, y = Hc, color = Sport_group))+ 
  geom_boxplot(size = 0.75)+
  ylab("Hematocrit Level")+
  xlab("Sport Group")+
  ggtitle("Figure 7: Hematocrit Levels by Various Sport Groups
                  for 202 Australian Athletes")+
  scale_color_manual(values = color_blind_friendly, name = "Model Version")+
  theme_classic()

## Boxplot Hg

Boxplot_Hg_Sport <- 
  ggplot(Athletes, aes(x = Sport_group, y = Hg, color = Sport_group))+ 
  geom_boxplot(size = 0.75)+
  ylab("Hemoglobin Level")+
  xlab("Sport Group")+
  ggtitle("Figure 8: Hemoglobin Levels by Various Sport Groups
                  for 202 Australian Athletes")+
  scale_color_manual(values = color_blind_friendly, name = "Model Version")+
  theme_classic()

## Boxplot Ferr

Boxplot_Ferr_Sport <- 
  ggplot(Athletes, aes(x = Sport_group, y = Ferr, color = Sport_group))+ 
  geom_boxplot(size = 0.75)+
  ylab("Plasma Ferratin Level")+
  xlab("Sport Group")+
  ggtitle("Figure 10: Plasma Ferritin Levels by Various Sport Groups
                  for 202 Australian Athletes")+
  scale_color_manual(values = color_blind_friendly, name = "Model Version")+
  theme_classic()

## Boxplot BMI

Boxplot_BMI_Sport <- 
  ggplot(Athletes, aes(x = Sport_group, y = BMI, color = Sport_group))+ 
  geom_boxplot(size = 0.75)+
  ylab("Body Mass Index")+
  xlab("Sport Group")+
  ggtitle("Figure 4: Body Mass Index by Various Sport Groups
                  for 202 Australian Athletes")+
  scale_color_manual(values = color_blind_friendly, name = "Model Version")+
  theme_classic()

## Boxplot SSF

Boxplot_SSF_Sport <- 
  ggplot(Athletes, aes(x = Sport_group, y = SSF, color = Sport_group))+ 
  geom_boxplot(size = 0.75)+
  ylab("Sum of Skin Folds")+
  xlab("Sport Group")+
  ggtitle("Figure 9: Sum of Skin Folds by Various Sport Groups
                  for 202 Australian Athletes")+
  scale_color_manual(values = color_blind_friendly, name = "Model Version")+
  theme_classic()

## Boxplot Bfat

Boxplot_Bfat_Sport <- 
  ggplot(Athletes, aes(x = Sport_group, y = Bfat, color = Sport_group))+ 
  geom_boxplot(size = 0.75)+
  ylab("Body Fat Percentage")+
  xlab("Sport Group")+
  ggtitle("Figure 11: Body Fat Percentage by Various Sport Groups
                  for 202 Australian Athletes")+
  scale_color_manual(values = color_blind_friendly, name = "Model Version")+
  theme_classic()

# Conditional Probability Barplot: Sex

Athletes$Sport_group <- as.factor(Athletes$Sport_group)

levels(as.factor(Athletes$Sport_group))

# get counts of vars
counts <- table(Athletes$Sport_group, as.factor(Athletes$Sex))

# get percentages of vars
pcnts <- scale(counts, FALSE, colSums(counts))*100
```

```{r, echo = FALSE, warning = FALSE, fig.width = 12, fig.height = 6}
grid.arrange(Boxplot_Ht_Sport, Boxplot_Wt_Sport, ncol = 2)
```

```{r, echo = FALSE, warning = FALSE, fig.width = 12, fig.height = 6}
grid.arrange(Boxplot_LBM_Sport, Boxplot_BMI_Sport, ncol = 2)
```

```{r, echo = FALSE, warning = FALSE, fig.width = 12, fig.height = 6}
grid.arrange(Boxplot_RCC_Sport, Boxplot_WCC_Sport, ncol = 2)
```

```{r, echo = FALSE, warning = FALSE, fig.width = 12, fig.height = 6}
grid.arrange(Boxplot_Hc_Sport, Boxplot_Hg_Sport, ncol = 2)
```

```{r, echo = FALSE, warning = FALSE, fig.width = 12, fig.height = 6}
grid.arrange(Boxplot_SSF_Sport, Boxplot_Ferr_Sport, ncol = 2)
```

```{r, echo = FALSE, warning = FALSE, fig.width = 6, fig.height = 3}
grid.arrange(Boxplot_Bfat_Sport, ncol = 1)
```

```{r, echo = FALSE, warning = FALSE, fig.width = 12, fig.height = 6}
# plot SEX/SPORT barplot
bp_Sex_Sport <- barplot(pcnts, beside=TRUE, col=c("#CC7917", "#0072B2", "#CC79A7"), ylab="Frequency (%)", border=NA)
legend("topright", legend=c("Ball", "Track", "Water/Gym"), bty="n", fill=c("#CC7917", "#0072B2", "#CC79A7"), border=NA)
text(bp_Sex_Sport, 1, round(pcnts, 2), cex=1, pos=3, col=c("black"))
title(main="Figure 12: Frequency of Males and Females Across Three Sport Groups for 202 Australian Athletes", xlab="Sex (Male = 0, Female = 1)")
```

```{r, echo = FALSE, include = FALSE}
############# Model Building Single and Double CV

### Single CV

set.seed(3)

# Single 10-fold CV
train_method_Athletes = trainControl(method="cv", number=10)

# specify data to be used for model selection - best for future integration into doubleCV
dataused = Athletes

# K Values integers in steps of 2 up to 146
kvals <- c(c(1:73)*2)

# mtry integers 1:8

mtry_vals <- c(1:8)

# Single CV

# KNN
fit_singlecaret_knn_athletes = train(Sport_group ~ ., data = Athletes, 
                       method = "knn", preProcess = c("center","scale"), 
                       tuneGrid = expand.grid(k = kvals), metric = "Accuracy",
                       trControl = train_method_Athletes)
  
# Random Forest
fit_singlecaret_rf_athletes = train(Sport_group ~ ., 
                        data = Athletes, method = "rf", metric = "Accuracy",
                        tuneGrid = expand.grid(mtry = mtry_vals),
                        trControl = train_method_Athletes)

# Best Tunes:
fit_singlecaret_knn_athletes$bestTune
fit_singlecaret_rf_athletes$bestTune

# Accuracy Maximums
max(fit_singlecaret_knn_athletes$results$Accuracy)
max(fit_singlecaret_rf_athletes$results$Accuracy)

# Accuracy is Maximzed at Random Forest with mtry = 1 and Accuracy of 0.7122

### Create Single CV Summary Table

Model <- c("K-Nearest Neighbord", "Random Forest")
Parameter_Range <- c("K = (1:73)*2", "mtry = 1:8")
Optimal_Parameter <- c(" K = 6", "mtry = 1")
Maximum_Accuracy <- c("0.6593", "0.7122")

SingleCV_Results <- as.data.frame(cbind(Model, Parameter_Range, Optimal_Parameter, Maximum_Accuracy))

fit_singlecaret_rf_athletes$finalModel$confusion
```

```{r, echo = FALSE}
### Output table of Single CV Results

knitr::kable(SingleCV_Results, "simple", caption = "Table 1: Results of Single 10-Fold Cross Validation with K-Nearest Neighbors and Random Forest for the Athletes Dataset")
```

```{r, echo = FALSE, include = FALSE, warning = FALSE}

### Double CV

set.seed(3) # For consistency of cross validation

# inner 10-fold CV
train_method_Athletes = trainControl(method="cv", number=10)

# outer 5-fold CV
n_Athletes = dim(Athletes)[1]
nfolds_outer = 5  # number of fold in outer CV
groups = rep(1:nfolds_outer,length=n_Athletes)  #produces list of group labels
cvgroups = sample(groups,n_Athletes)  #orders randomly

# Define Prediction Storage Vector
predicted_Athletes_outer <- factor(rep(NA, n_Athletes), 
                                   levels = levels(Athletes$Sport_group))

# K Values integers in steps of 2 up to 146
kvals <- c(c(1:73)*2)

# mtry integers 1:8

mtry_vals <- c(1:8)

for (j in 1:nfolds_outer) {
  in_train = (cvgroups != j)
  in_valid = (cvgroups == j) 
  traindata = Athletes[in_train,]
  validdata = Athletes[in_valid,]
  
  dataused_athletes = traindata  

  ################ Step 1. ##############
  # cross-validation of various classification models
  
  # KNN
  fit_caret_knn_athletes = train(Sport_group ~ ., data = dataused_athletes, 
                       method = "knn", preProcess = c("center","scale"), 
                       tuneGrid = expand.grid(k = kvals), metric = "Accuracy",
                       trControl = train_method_Athletes)
  
  # Random Forest
  fit_caret_rf_athletes = train(Sport_group ~ ., 
                        data = dataused_athletes, method = "rf", metric = "Accuracy",
                        tuneGrid = expand.grid(mtry = mtry_vals),
                        trControl = train_method_Athletes)
  
  ################ Step 2. ##############
  
  ## Store Accuracy Values 
  
  allACCURACYvaluesCV_kNN = fit_caret_knn_athletes$results$Accuracy
  allACCURACYvaluesCV_rf = fit_caret_rf_athletes$results$Accuracy
  
  all_train_output <- list(fit_caret_knn_athletes, fit_caret_rf_athletes)

  ###	  output all_Accuracy_CV    ###
  ###	   and all_train_output     ###
  
  ################ Step 3. ##############
  
  # Select Max KNN Accuracy
  
  which_best_kNN <- which.max(allACCURACYvaluesCV_kNN)
  AccuracyvalueCV_kNN <- allACCURACYvaluesCV_kNN[which_best_kNN]
  bestk <- kvals[which_best_kNN]
  best_modelfit_kNN <- fit_caret_knn_athletes$finalModel
  
  # Select Max RF Accuracy
  
  which_best_rf <- which.max(allACCURACYvaluesCV_rf)
  AccuracyvalueCV_rf<- allACCURACYvaluesCV_rf[which_best_rf]
  bestmtry <- mtry_vals[which_best_rf]
  best_modelfit_rf <- fit_caret_rf_athletes$finalModel
  
  # Define Possible Best Models
  
  all_methods <- c("kNN", "Random Forest")
  all_best_hyperparameters <- list(bestk, bestmtry)
  all_methods_max_CV_Accuracy <- c(AccuracyvalueCV_kNN, AccuracyvalueCV_rf)
  
  # print best model
  cat("\n\nThe best model in outer-loop", j, 
      "is", all_methods[which.max(all_methods_max_CV_Accuracy)], 
      "\nwith",
      as.character(all_best_hyperparameters[[which.max(all_methods_max_CV_Accuracy)]]), 
      "and Accuracy=", all_methods_max_CV_Accuracy[which.max(all_methods_max_CV_Accuracy)]
  )

  cat('\nAt time', format(Sys.time(),'%H:%M:%S'))  # checking how long to run

  # store all of the train-function outputs in a list
  # same order as the all_methods
  all_fit_caret_output <- list(fit_caret_knn_athletes, 
                               fit_caret_rf_athletes)

  # programmatically identify the utilized output from `train` function
  best_fit_caret_output <- all_fit_caret_output[[which.max(all_methods_max_CV_Accuracy)]]

  # Make Predictions For Sport_Group With Best Model
  pred_Sport <- best_fit_caret_output %>% predict(validdata)
  
  # add to predicted_Domestic_outer at locations of validation data
  predicted_Athletes_outer[in_valid] <- pred_Sport
}

# Honest Assessment
table(predicted_Athletes_outer,Athletes$Sport_group)
Accuracy_CV = sum(predicted_Athletes_outer == Athletes$Sport_group)/n_Athletes
Accuracy_CV

# Confusion Matrix

# create new confusion matrix for Actual + Predicted labels
conf_athletes <- table(Actual = Athletes$Sport_group, Predicted = predicted_Athletes_outer)

conf_data_athletes <- as.data.frame(as.table(conf_athletes))

### Results Table Creation
Outer_Loop <- c(1:5)
Optimal_Model <- c("Random Forest", "Random Forest", "Random Forest", "Random Forest", "Random Forest")
Optimal_Tune <- c("mtry = 5", "mtry = 4", "mtry = 6", "mtry = 3", "mtry = 1")
Maximum_Accuracy <- c("0.6623", "0.6909", "0.7226", "0.7228", "0.6912")

DoubleCV_Results <- as.data.frame(cbind(Outer_Loop, Optimal_Model, Optimal_Tune, Maximum_Accuracy))
```

```{r, echo = FALSE, warning = FALSE, fig.width = 6}
### Table of Double CV Results

knitr::kable(DoubleCV_Results, "simple", caption = "Table 2: Results of Double 5-Fold Cross Validation with K-Nearest Neighbors and Random Forest for the Athletes Dataset")

### Confusion Matrix For Double CV

ggplot(conf_data_athletes, aes(x = Predicted, y = Actual, fill = Freq)) +
  geom_tile() + theme_bw() + coord_equal() +
  ggtitle("Figure 13: Athletes Confusion Matrix for Honest 
Predictions Assessment with 5-Fold Double CV ")+
  labs(caption = "Honest Accuracy = 0.6881")+
  scale_fill_distiller(palette = "Blues", direction = 1) +
  guides(fill = FALSE) +
  geom_text(aes(label = Freq), color = "black", size = 10)
```

```{r, echo = FALSE, include = FALSE}
################ Model Assessment

### Test Var Imp Plot

varImpPlot(fit_singlecaret_rf_athletes$finalModel)

levels(Athletes$Sport_group)

### Partial Plots SSF

source("gf_partialPlot.R")
Ball_PD_SSF <- 
  gf_partialPlot(fit_singlecaret_rf_athletes, Athletes, x.var = "SSF", which.class = "ball") %>% gf_labs(title = "Increasing Sum of Skin Folds Increases
the Chances of a Ball Athlete Prediction")

Track_PD_SSF <- 
  gf_partialPlot(fit_singlecaret_rf_athletes, Athletes, x.var = "SSF", which.class = "track") %>% gf_labs(title = "Increasing Sum of Skin Folds Decreases
the Chances of a Track Athlete Prediction")

water_gym_PD_SSF <- 
  gf_partialPlot(fit_singlecaret_rf_athletes, Athletes, x.var = "SSF", which.class = "water/gym") %>% gf_labs(title = "Increasing Sum of Skin Folds Increases then
Decreases the Chances of a Water/Gym Athlete Prediction")

### Partial Plots Hg

Ball_PD_Hg <- 
  gf_partialPlot(fit_singlecaret_rf_athletes, Athletes, x.var = "Hg", which.class = "ball") %>% gf_labs(title = "Increasing Hemoglobin Blood Levels Decreases
the Chances of a Ball Athlete Prediction")

Track_PD_Hg <- 
  gf_partialPlot(fit_singlecaret_rf_athletes, Athletes, x.var = "Hg", which.class = "track") %>% gf_labs(title = "Increasing Hemoglobin Blood Levels Increases
the Chances of a Track Athlete Prediction")

water_gym_PD_Hg <- 
  gf_partialPlot(fit_singlecaret_rf_athletes, Athletes, x.var = "Hg", which.class = "water/gym") %>% gf_labs(title = "Increasing Hemoglobin Blood Levels Increases then
Decreases the Chances of a Water/Gym Athlete Prediction")
```

```{r, echo = FALSE, fig.width = 12}
### Variable Importance Best Model

varImpPlot(fit_singlecaret_rf_athletes$finalModel, main = "Figure 14: Variable Importance via Gini-Index Decrease for the Best Random Forest Model from 10-Fold Single CV")
```

```{r, echo = FALSE, fig.width = 17, fig.height = 6}
grid.arrange(Ball_PD_SSF,Track_PD_SSF, water_gym_PD_SSF, ncol = 3, top = "Figure 15: Partial Dependencies of SSF for the Australian Sports Group Response Variable")
```

```{r, echo = FALSE, fig.width = 17, fig.height = 6}
grid.arrange(Ball_PD_Hg,Track_PD_Hg, water_gym_PD_Hg, ncol = 3, top = "Figure 16: Partial Dependencies of Hg for the Australian Sports Group Response Variable")
```

```{r, echo = FALSE, include = FALSE}
## Calculate No Information Rate
80/202

## Identify Model Accuracy Compared to No Information Rate
68.81-39.60
```















